Introduction:
=============

This document provides information on the implementation side
design decisions and the blueprint of the implementation itself.


Directory structure:
====================

* /etc/guerillabackup: This is the default configuration directory.
  * config: This is the main GuerillaBackup configuration file.
    Settings can be overridden e.g. in unit configuration files.
  * keys: This directory is the default backup encryption key
    location. Currently this is the home directory of a GnuPG
    key store.
  * lib-enabled: This directory is included in the site-path by
    default. Add symlinks to include specific Python packages
    or machine/organisation specific code.
  * units: The units directory contains the enabled backup data
    generation units. To enable a unit, a symbolic link to the
    unit definition file has to be created. The name of the symlink
    has to consist only of letters and numbers. For units with
    an associated configuration file named "[unitname].config",
    configuration parameters from the main configuration file
    can be overridden within the unit-specific configuration.
* /var/lib/guerillabackup: This directory is usually only readable
  by root user unless transfer agents with different UID are configured.
  * data: where backuped data from local backups is stored, usually
    by the default sink.
  * state: State persistency directory for all backup procedures.
  * state/generators/[UnitName]: File or directory to store state
    data for a given backup unit.
  * state/agents: Directory to store additional information of
    local backup data processing or remote transfer agents.
* /var/run/guerillabackup: This directory is used to keep data,
  only needed while guerillabackup tools are running. This data
  can be discarded on reboot.
  * transfer.socket: Default socket location for TransferServices.


Library functions:
==================

* Configuration loading:

Configuration loading happens in 2 stages:

  * Loading of the main configuration.
  * Loading of a component/module specific overlay configuration.
    This is allows tools to perform modularized tasks, e.g. a backup
    generator processing different sources, to apply userdefined
    configuration alterations to the configuration of a single unit.
    The overlay configuration is then merged with the main configuration.

Defaults have to be set in the main configuration. A tool may
refuse to start when required default values are missing in the
configuration.


Backup Generator:
=================

* Process pipelines:

Pipeline implementation is designed to support both operating
system processes using only filedescriptors for streaming and
pure Python processes, that need to be run in a separate thread
or are polled for normal operation.

  * Error handling:

Standard way to get processing errors is by calling the doProcess
method, even when process is asynchronous. On error, the method
should always return the same error message for a broken process
until stop() is called.

One error variant is, that operating system processes did not
read all input from their input pipes and some data remains in
buffers. This error has to be reported to the caller either from
doProcess() or stop(), whatever comes first. The correct detection
of input might fail, if a downstream component is stopped while
the upstream is running and writing or flushing data to a pipe
after the checks.


Policy Based Data Synchronization:
==================================

To support various requirements, e.g. decentraliced backup generation
with secure secure spooling, asynchronous transfers, a the "TransferService",
a component for synchronization is required, see "doc/Design.txt"
section "Synchronization" for design information.

The implementaion of "TransferService" orchestrates all components
required related to following functional blocks:

* ConnectorService: This service provides functions to establish
  connectivity to other "TransferService" instances. Currently
  only "SocketConnectorService" together with protocol handler
  "JsonStreamServerProtocolRequestHandler" is supported. The
  service has to care about authentication and basic service
  access authorization.

* Policies: Policies define, how the "TransferService" should
  interact with other "TransferService" instances. There are
  two types of policies, "ReceiverTransferPolicy" for incoming
  transfers and "SenderTransferPolicy" for transmitting data.
  See "ReceiverStoreDataTransferPolicy", "SenderMoveDataTransferPolicy",
  for currently supported policies.

* Storage: A storage to store, fetch and delete StorageBackupDataElements.
  Some storages may support storing of custom annotation data
  per element. This can then be used in policies to perform policy
  decisions, e.g. to priotise sending of files according to tags.
  Current storage implementation is "DefaultFileStorage".

* TransferAgent: The agent keeps track of all current connections
  created via the ConnectorService. It may control load balancing
  between multiple connections. Current available agent implementation
  is "SimpleTransferAgent".


Classes and interfaces:

* ClientProtocolInterface:

Classes implementing this interface are passed to the TransferAgent
by the ConnectorService to allow outbound calls to the other agent.

* ConnectorService:

A service to establish in or outbound connections to an active
TransferAgent. Implementation will vary depending on underlying
protocol, e.g. TCP, socket, ... and authentication type, which
is also handled by the ConnectorService.

* DefaultFileStorage:

This storage implementation stores all relevant information on
the filesystem, supporting locking and extra attribute handling.
It uses the element name to create the storage file names, appending
"data", "info" or "lock" to it for content, meta information
storage and locking. Extra attribute data is stored in by using
the attribute name as file extension. Thus extensions from above
but also ones containing dashes or dots are not allowed.

* JsonStreamServerProtocolRequestHandler:

This handler implements a minimalistic JSON protocol to invoke
ServerProtocolInterface methods. See "doc/Design.txt" section
"Transmission protocol" for protocol design information.

* ReceiverStoreDataTransferPolicy:

This class defines a receiver policy, that attempts to fetch all
data elements offered by the remote transfer agent.

* ReceiverTransferPolicy:

This is the common superinterface of all receiver transfer policies.

* ServerProtocolInterface:

This is the server side protocol adapter to be provided to the
transfer service to forward remote requests to the local SenderPolicy.

* SenderMoveDataTransferPolicy(SenderTransferPolicy):

This is a simple sender transfer policy just advertising all resources
for transfer and removing them or marking them as transfered as
soon as remote side confirms sucessful transfer. A file with a
mark will not be offered for download any more.
  * applyPolicy(): deletes the file when transfer was successful.

* SenderTransferPolicy:

This is the common superinterface of all sender side transfer
policies. A policy implementation may require to adjust the internal
state after data was transfered.
  * queryBackupDataElements(): return an iterator over all elements
    eligible for transfer by the current policy. The query may
    support remote side supplied query data for optimization.
    This should of course only be used when the remote side knows
    the policy.
  * applyPolicy(): update internal state after data transfer
    was rejected, attempted or even successful.

* SocketConnectorService:

This is currently the only ConnectorService available. It accepts
incoming connections on a local UNIX socket. Authentication and
socket access authorization has to be handled UNIX permissions
or integration with other tools, e.g. "socat". For each incoming
connection it uses a "JsonStreamServerProtocolRequestHandler"
protocol handler.

* TransferAgent:

This class provides the core functionality for in and outbound
transfers. It has a single sender or receiver transfer policy
or both attached. Protocol connections are attached to it using
a ConnectorService. The agent does not care about authentication
any more: everything relevant for authorization has to be provided
by the ConnectorService and stored to the TransferContext.
